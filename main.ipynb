{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 13:37:28.764090: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-21 13:37:28.873741: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 13:37:29.680534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "import cv2\n",
    "import imutils\n",
    "import requests\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from vidgear.gears import CamGear\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "[]\n",
      "<function is_built_with_cuda at 0x7fdf84d50550>\n",
      "\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 13:37:30.645278: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-08-21 13:37:30.645306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: ITZ\n",
      "2023-08-21 13:37:30.645309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: ITZ\n",
      "2023-08-21 13:37:30.645412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.86.5\n",
      "2023-08-21 13:37:30.645424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.86.5\n",
      "2023-08-21 13:37:30.645426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.86.5\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR']  = 'cuda_malloc_async'\n",
    "print(tf.__version__)  # 2.13.0-rc2\n",
    "print(tf.config.list_physical_devices('GPU')) # [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "print(tf.test.is_built_with_cuda)  # <function is_built_with_cuda at 0x169361d00>\n",
    "print(tf.test.gpu_device_name())  # /device:GPU:0\n",
    "print(tf.config.get_visible_devices())  # [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model if not already downloaded\n",
    "if not os.path.isdir('mobilenet_v2_140_224'):\n",
    "    if not os.path.isfile('mobilenet_v2_140_224.1.zip'):\n",
    "        !wget https://github.com/GantMan/nsfw_model/releases/download/1.2.0/mobilenet_v2_140_224.1.zip\n",
    "        !unzip mobilenet_v2_140_224.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 5), dtype=float32, numpy=\n",
       "array([[0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276],\n",
       "       [0.28783095, 0.20058176, 0.49027213, 0.01533243, 0.00598276]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model('mobilenet_v2_140_224')\n",
    "# Test model\n",
    "model(np.zeros((64, 224, 224, 3)))  # array([[0.001, 0.999]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawings\n",
      "hentai\n",
      "neutral\n",
      "porn\n",
      "sexy\n",
      "tf.Tensor([[7.0968449e-02 1.3347461e-02 9.1523635e-01 3.0026623e-04 1.4752209e-04]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Get labels\n",
    "labels = []\n",
    "with open('mobilenet_v2_140_224/class_labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "for l in labels:\n",
    "    print(l)\n",
    "\n",
    "\n",
    "output = model(tf.random.uniform([1, 224, 224, 3]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GStreamer:                   NO\n"
     ]
    }
   ],
   "source": [
    "# Find GStreamer version\n",
    "buildInfo = cv2.getBuildInformation()\n",
    "SUPPORT_GSTREAMER = True\n",
    "for line in buildInfo.split('\\n'):\n",
    "    if 'GStreamer' in line:\n",
    "        print(line)\n",
    "        if \"NO\" in line:\n",
    "            SUPPORT_GSTREAMER = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/thJgU9jkdU4\n",
      "[youtube] thJgU9jkdU4: Downloading webpage\n",
      "[youtube] thJgU9jkdU4: Downloading ios player API JSON\n",
      "[youtube] thJgU9jkdU4: Downloading android player API JSON\n",
      "[youtube] thJgU9jkdU4: Downloading m3u8 information\n",
      "[info] thJgU9jkdU4: Downloading 1 format(s): 616+251\n",
      "[download] Rammstein - Dicke Titten (Official Video) [thJgU9jkdU4].webm has already been downloaded\n",
      "[youtube] Extracting URL: https://youtu.be/thJgU9jkdU4\n",
      "[youtube] thJgU9jkdU4: Downloading webpage\n",
      "[youtube] thJgU9jkdU4: Downloading ios player API JSON\n",
      "[youtube] thJgU9jkdU4: Downloading android player API JSON\n",
      "[youtube] thJgU9jkdU4: Downloading m3u8 information\n",
      "Rammstein - Dicke Titten (Official Video) [thJgU9jkdU4].webm\n"
     ]
    }
   ],
   "source": [
    "youtube_video_id = \"thJgU9jkdU4\"\n",
    "url = \"https://youtu.be/\" + youtube_video_id\n",
    "source = None\n",
    "filename_ydl = None\n",
    "if not SUPPORT_GSTREAMER:\n",
    "    # Download instead of streaming\n",
    "    if \"youtu\" in url:\n",
    "        with YoutubeDL() as ydl:\n",
    "            ydl.download([url])\n",
    "            info = ydl.extract_info(url, download=False)\n",
    "            # Get file path\n",
    "            filename_ydl = ydl.prepare_filename(info)\n",
    "            print(filename_ydl)\n",
    "    else:\n",
    "        # Download video\n",
    "        filename_ydl = url.split('/')[-1]\n",
    "        if not os.path.isfile(filename_ydl):\n",
    "            resp = requests.get(url, stream=True)\n",
    "            with open(filename_ydl, 'wb') as f:\n",
    "                for chunk in resp.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsToColor = {\n",
    "    \"drawings\": (0, 0, 0),\n",
    "    \"hentai\": (0, 0, 255),\n",
    "    \"neutral\": (0, 0, 0),\n",
    "    \"porn\": (0, 255, 0),\n",
    "    \"sexy\": (255, 0, 0)\n",
    "}\n",
    "\n",
    "triggerOnLabels = [\"porn\", \"sexy\", \"hentai\"]\n",
    "\n",
    "directory = (filename_ydl or url).split('/')[-1].split('.')[0]\n",
    "\n",
    "os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:45:05\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mEnabling Threaded Queue Mode for the current video source!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: Rammstein - Dicke Titten (Official Video) [thJgU9jkdU4].webm\n",
      "(1080, 1920, 3)\n",
      "Square X Count: 8\n",
      "Square Y Count: 4\n",
      "Start Offset X: 1792\n",
      "Start Offset Y: 896\n",
      "Offset X: 64\n",
      "Offset Y: 92\n",
      "FPS: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:53:12\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mTerminating processes.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# infinite loop\n",
    "if not SUPPORT_GSTREAMER:\n",
    "    print(\"Using file: \" + filename_ydl)\n",
    "    source = CamGear(source=filename_ydl, logging=True)\n",
    "else:\n",
    "    source = CamGear(source=url, stream_mode = True, logging=True)\n",
    "\n",
    "DISABLE_CHUNKING = True\n",
    "\n",
    "stream = source.start() # YouTube Video URL as input\n",
    "# Print resolution of stream\n",
    "frame = stream.read()\n",
    "if frame is None: \n",
    "    raise Exception(\"Unable to read stream from source\")\n",
    "print(frame.shape)\n",
    "# How many 224x224 square you can fit in the frame\n",
    "squareXCount = frame.shape[1] // 224\n",
    "squareYCount = frame.shape[0] // 224\n",
    "print(\"Square X Count: \" + str(squareXCount))\n",
    "print(\"Square Y Count: \" + str(squareYCount))\n",
    "\n",
    "# Offset to center the squares based on leftover pixels\n",
    "startOffsetX = (squareXCount * 224)\n",
    "startOffsetY = (squareYCount * 224)\n",
    "\n",
    "# How many pixels are left over\n",
    "leftoverX = frame.shape[1] - startOffsetX\n",
    "leftoverY = frame.shape[0] - startOffsetY\n",
    "\n",
    "print(\"Start Offset X: \" + str(startOffsetX))\n",
    "print(\"Start Offset Y: \" + str(startOffsetY))\n",
    "\n",
    "offsetX = int(leftoverX  / 2)\n",
    "offsetY = int(leftoverY / 2) \n",
    "\n",
    "print(\"Offset X: \" + str(offsetX))\n",
    "print(\"Offset Y: \" + str(offsetY))\n",
    "\n",
    "fps = stream.framerate\n",
    "print(\"FPS: \" + str(fps))\n",
    "last_triggred_frame = 0\n",
    "frame_count = 0\n",
    "last_frame_time = time.time()\n",
    "while True:\n",
    "    if frame_count % 100 == 0:\n",
    "        # Prevent TensorFlow memory leak\n",
    "        gc.collect()\n",
    "    frame = stream.read()\n",
    "    # read frames\n",
    "\n",
    "    # check if frame is None\n",
    "    if frame is None:\n",
    "        #if True break the infinite loop\n",
    "        break\n",
    "    frame_count += 1\n",
    "    # do something with frame here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect people in the image\n",
    "    #(rects, weights) = hog.detectMultiScale(gray, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "    #pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "    \n",
    "    #for (x, y, w, h) in pick:\n",
    "    #    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    # Divide frame into 224x224 squares by drawing rectangles\n",
    "    # For each square, predict if it is NSFW\n",
    "    # If NSFW, blur the square\n",
    "    batchOfBatch = []\n",
    "    for i in range(frame.shape[0] // 224):\n",
    "        if DISABLE_CHUNKING: break\n",
    "        batch = []\n",
    "        for j in range(frame.shape[1] // 224):\n",
    "            square_points = [(j * 224 + offsetX, i * 224 + offsetY), (j * 224 + 224 + offsetX, i * 224 + 224 + offsetY)]\n",
    "            # Crop square\n",
    "            square = frame[square_points[0][1]:square_points[1][1], square_points[0][0]:square_points[1][0]]\n",
    "            \n",
    "            # Write square to file\n",
    "            #cv2.imwrite(\"square.jpg\", square)\n",
    "            # Resize square to 224x224 \n",
    "            square = cv2.resize(square, (224, 224))\n",
    "            # Convert square to RGB\n",
    "            square = cv2.cvtColor(square, cv2.COLOR_BGR2RGB)\n",
    "            # Convert square to float32\n",
    "            square = square.astype(np.float32)\n",
    "            # Normalize square\n",
    "            square /= 255\n",
    "            # Add square to batch\n",
    "            batchOfBatch.append(square)\n",
    "            #print(\"Shape of square: \" + str(square.shape))\n",
    "            \n",
    "    original_frame = frame.copy()\n",
    "    og = cv2.resize(frame, (224, 224))\n",
    "    og = cv2.cvtColor(og, cv2.COLOR_BGR2RGB)\n",
    "    og = og.astype(np.float32)\n",
    "    og /= 255\n",
    "    batchOfBatch.append(og)\n",
    "    batch = np.array(batchOfBatch)\n",
    "    predictions = model.predict(batch, verbose=None, batch_size=64)\n",
    "    triggered = False\n",
    "    indexBatch = 0\n",
    "    for i in range(frame.shape[0] // 224):\n",
    "        if DISABLE_CHUNKING: break\n",
    "        # Predict NSFW for batch\n",
    "        # Blur NSFW squares\n",
    "        for j in range(frame.shape[1] // 224):\n",
    "            prediction = predictions[indexBatch]\n",
    "            square_points = [(j * 224 + offsetX, i * 224 + offsetY), (j * 224 + 224 + offsetX, i * 224 + 224 + offsetY)]\n",
    "            # Write prediction on frame\n",
    "            for k in range(5):\n",
    "                if prediction[k] > 0.7 and labels[k] in triggerOnLabels:\n",
    "                    #triggered = True\n",
    "                    frame[i * 224 + offsetY:i * 224 + 224 + offsetY, j * 224 + offsetX:j * 224 + 224 + offsetX] = cv2.blur(frame[i * 224 + offsetY:i * 224 + 224 + offsetY, j * 224 + offsetX:j * 224 + 224 + offsetX], (50, 50))\n",
    "                text = labels[k] + \": \" + str(round(prediction[k], 2))\n",
    "                color = labelsToColor[labels[k]]\n",
    "                cv2.rectangle(frame, (j * 224 + offsetX, i * 224 + offsetY + 20 * k), (j * 224 + offsetX + int(prediction[k] * 100), i * 224 + offsetY + 20 * (k + 1)), color, -1)\n",
    "                cv2.putText(frame, text, (j * 224 + offsetX, i * 224 + offsetY + 25 * k), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "                \n",
    "            cv2.rectangle(frame, square_points[0], square_points[1], (0, 0, 255), 2)\n",
    "            \n",
    "            indexBatch += 1\n",
    "    original_prediction = predictions[-1]\n",
    "    main_trigger_reason = \"\"\n",
    "    for k in range(5):\n",
    "        text = labels[k] + \": \" + str(round(original_prediction[k], 2))\n",
    "        color = labelsToColor[labels[k]]\n",
    "        cv2.rectangle(frame, (0, 20 * (k+1)), (int(original_prediction[k] * 100), 20 * (k + 1)), color, -1)\n",
    "        cv2.putText(frame, text, (0, 25 * (k+1)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        if original_prediction[k] > 0.65 and labels[k] in triggerOnLabels:\n",
    "            triggered = True\n",
    "            main_trigger_reason = main_trigger_reason + \"[\" + labels[k] + \" \" + str(round(original_prediction[k], 2)) + \"]\"\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if triggered:\n",
    "        cv2.putText(frame, \"NSFW DETECTED\", (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        # Save original frame if more than fps * n frames have passed since last trigger\n",
    "        if frame_count - last_triggred_frame > fps * 0.25:\n",
    "            cv2.imwrite(directory + \"/\" + str(frame_count) + main_trigger_reason + \".jpg\", original_frame)\n",
    "            last_triggred_frame = frame_count\n",
    "    \n",
    "    # Get FPS measurement\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - last_frame_time)\n",
    "    last_frame_time = current_time\n",
    "    cv2.putText(frame, \"FPS: \" + str(round(fps, 2)), (int(frame.shape[1]/2), 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Output Frame\", frame)\n",
    "    # Show output window\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # check for 'q' key-press\n",
    "    if key == ord(\"q\"):\n",
    "        #if 'q' key-pressed break out\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# close output window\n",
    "\n",
    "# safely close video stream.\n",
    "stream.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nhentai-datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
